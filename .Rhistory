p.eval = 100
H = lapply(1:length(p.seq), function(l){seq(1, 3/p.seq[l], -0.05)})
# Parameter OU Process
theta = 2; sigma = 3
# Standard deviation for additional errors
sd = 0.75
bw_comparison = list()
cl = parallel::makeCluster(parallel::detectCores( ) - 1)
future::plan(future::cluster)
##### Figure 3.3 #####
bw_comparison_tbl = Reduce(rbind, bw_comparison) |>
as_tibble() |>
rename(n = V1, p = V2, h = V3, sup.err = V4) |>
mutate(p = as.factor(p), n = as.factor(n))
library(tictoc)
##### calculations #####
N = 10
p.seq = c(20,50)
n. seq = c(100, 150)
n.seq = c(100, 150)
p.eval= 25
H = lapply(1:length(p.seq), function(l){seq(1, 3/p.seq[l], -0.05)})
# Parameter OU Process
theta = 2; sigma = 3
# Standard deviation for additional errors
sd = 0.75
bw_comparison = list()
cl = parallel::makeCluster(parallel::detectCores( ) - 1)
future::plan(future::cluster)
for(l in 1:length(p.seq)){
tic()
bw_comparison[[l]] = matrix(t(future_sapply(1:length(H[[l]]), FUN = function(k)
{
bandwidth_evaluation(H[[l]][k], p.seq[l], p.eval, n.seq, N,
cov_ou, list(theta = theta, sigma = sigma),
OU, list(alpha = theta, sigma = sigma, x0 = 0),
eps.arg = list(sd = sd))
},
future.seed = T)),ncol = 4)
cat("p =", p.seq[l], "done.")
toc()
}
library(future.apply)
for(l in 1:length(p.seq)){
tic()
bw_comparison[[l]] = matrix(t(future_sapply(1:length(H[[l]]), FUN = function(k)
{
bandwidth_evaluation(H[[l]][k], p.seq[l], p.eval, n.seq, N,
cov_ou, list(theta = theta, sigma = sigma),
OU, list(alpha = theta, sigma = sigma, x0 = 0),
eps.arg = list(sd = sd))
},
future.seed = T)),ncol = 4)
cat("p =", p.seq[l], "done.")
toc()
}
##### Figure 3.3 #####
bw_comparison_tbl = Reduce(rbind, bw_comparison) |>
as_tibble() |>
rename(n = V1, p = V2, h = V3, sup.err = V4) |>
mutate(p = as.factor(p), n = as.factor(n))
bw_comparison_tbl |>
filter(n == 400) |>
ggplot() +
geom_point(aes(x = h, y = sup.err, col = p, pch = p)) +
ylim(c(0.02, 0.52)) +
labs(title = "n = 400") +
my_theme
bw_comparison
Reduce(rbind, bw_comparison)
##### Figure 3.3 #####
bw_comparison_tbl = Reduce(rbind, bw_comparison) |>
as_tibble(.name_repair = "unique") |>
rename(n = V1, p = V2, h = V3, sup.err = V4) |>
mutate(p = as.factor(p), n = as.factor(n))
colnames(bw_comparison) = c("n", "p", "h", "sup.err")
warnings()
bw_comparison
colnames(bw_comparison) = c("n", "p", "h", "sup.err")
colnames(bw_comparison) = list(NULL, c("n", "p", "h", "sup.err"), NULL)
dim(bw_comparison)
is.arry(bw_comparison)
is.array(bw_comparison)
Reduce(rbind, bw_comparison)
Reduce(rbind, bw_comparison) |>
as_tibble()
Reduce(rbind, bw_comparison) |>
as_tibble() |>
rename(n = V1, p = V2, h = V3, sup.err = V4)
##### Figure 3.3 #####
bw_comparison_tbl = Reduce(rbind, bw_comparison) |>
as_tibble() |>
rename(n = V1, p = V2, h = V3, sup.err = V4) |>
mutate(p = as.factor(p), n = as.factor(n))
bw_comparison_tbl |>
filter(n == 400) |>
ggplot() +
geom_point(aes(x = h, y = sup.err, col = p, pch = p)) +
ylim(c(0.02, 0.52)) +
labs(title = "n = 400") +
my_theme
bw_comparison_tbl
bw_comparison_tbl |>
filter(n == 400) |>
ggplot() +
geom_point(aes(x = h, y = sup.err, col = p, pch = p)) +
# ylim(c(0.02, 0.52)) +
labs(title = "n = 400") +
my_theme
bw_comparison_tbl |>
#filter(n == 400) |>
ggplot() +
geom_point(aes(x = h, y = sup.err, col = p, pch = p)) +
# ylim(c(0.02, 0.52)) +
labs(title = "n = 400") +
my_theme
library(tictoc)
#### packages, code ####
library(ggplot2)
library(tidyverse)
library(biLocPol)
library(future.apply)
library(tictoc)
my_theme = theme_grey(base_size = 15) +
theme(plot.title = element_text(size = 14))
#  Figures 3.6
source("cov/functions.r")
load("cov/data/bw_comp_OU.RData") # load best bandwidths from comparison
cl = parallel::makeCluster(parallel::detectCores( ) - 1)
future::plan(future::cluster)
error_decomp_arr = array(0, c(length(p.seq), 6, length(n.seq)))
for(i in 1:length(n.seq)){
h_min = min_h_tibble |> filter(n == n.seq[i]) |> pull(h)
for (j in 1:length(p.seq)) {
tic()
weight                 = local_polynomial_weights(p.seq[j], h_min[j],
p.eval, parallel = T,
m = 1, del = 0,
parallel.environment = F)
error_decomp_arr[j,,i] = error_decomposition(weight, n.seq[i], N, parallel = T,
parallel.environment = F)
cat("n =", n.seq[i], "and p =", p.seq[j], "done. ")
toc()
}
}
for(i in 1:length(n.seq)){
h_min = min_h_tibble |> filter(n == n.seq[i]) |> pull(h)
for (j in 1:length(p.seq)) {
tic()
weight                 = local_polynomial_weights(p.seq[j], h_min[j],
p.eval, parallel = T,
m = 1, del = 0,
parallel.environment = F)
error_decomp_arr[j,,i] = error_decomposition(weight, n.seq[i], N, parallel = T, Gamma = cov_ou,
parallel.environment = F)
cat("n =", n.seq[i], "and p =", p.seq[j], "done. ")
toc()
}
}
#### packages, code ####
library(ggplot2)
library(tidyverse)
library(biLocPol)
my_theme = theme_grey(base_size = 15) +
theme(plot.title = element_text(size = 14))
library(tictoc)
my_theme = theme_grey(base_size = 15) +
theme(plot.title = element_text(size = 14))
#  Figures 3.4, 3.6
source("cov/functions.r")
one_fold_cv = list()
cl = parallel::makeCluster(parallel::detectCores( ) - 1)
future::plan(future::cluster)
for(l in 1:length(p.seq)){
tic()
one_fold_cv[[l]] =  lopocv_sim(N, n = 100, p.seq[l], H[[l]],
m = 1, w.parallel = T,
theta = theta, sigma = sigma, sd = sd)
cat("p =", p.seq[l], "done.")
toc()
}
##### setup #####
N = 1000
n.seq = c(50, 100, 200, 400)
p.seq = c(15, 25, 50, 75, 100)
p.eval = 100
H = lapply(1:length(p.seq), function(l){seq(1, 3/p.seq[l], -0.05)})
# Parameter OU Process
theta = 2; sigma = 3
# Standard deviation for additional errors
sd = 0.75
one_fold_cv = list()
cl = parallel::makeCluster(parallel::detectCores( ) - 1)
future::plan(future::cluster)
for(l in 1:length(p.seq)){
tic()
one_fold_cv[[l]] =  lopocv_sim(N, n = 100, p.seq[l], H[[l]],
m = 1, w.parallel = T,
theta = theta, sigma = sigma, sd = sd)
cat("p =", p.seq[l], "done.")
toc()
}
library(tictoc)
my_theme = theme_grey(base_size = 15) +
theme(plot.title = element_text(size = 14))
#  Figures 3.6
source("cov/functions.r")
N = 1000
n.seq = c(100, 300)
p.seq = c( 50,  75)
p.eval = 75
H = lapply(1:length(p.seq), function(l){seq(1, 3/p.seq[l], -0.05)})
# Parameter OU Process
theta = 2; sigma = 3
# Standard deviation for additional errors
sd = 0.75
##### m = 0 #####
m = 0
bw_comparison_OU_m0 = list()
bw_comparison_OU_m0_full = list()
cl = parallel::makeCluster(parallel::detectCores( ) - 1)
future::plan(future::cluster)
for(l in 1:length(p.seq)){
tic()
bw_comparison_OU_m0[[l]]      = matrix(t(future_sapply(1:length(H[[l]]), FUN = function(k)
{
bandwidth_evaluation(H[[l]][k], p.seq[l], p.eval, n.seq, N,
cov.ou, list(theta = theta, sigma = sigma),
OU, list(alpha = theta, sigma = sigma, x0 = 0),
eps.arg = list(sd = sd), m = m)
},
future.seed = T)),ncol = 4)
cat("p =", p.seq[l], "done.")
bw_comparison_OU_m0_full[[l]] = matrix(t(future_sapply(1:length(H[[l]]), FUN = function(k)
{
bandwidth_evaluation(H[[l]][k], p.seq[l], p.eval, n.seq, N,
cov.ou, list(theta = theta, sigma = sigma),
OU, list(alpha = theta, sigma = sigma, x0 = 0),
eps.arg = list(sd = sd), m = m, grid.type = "without diagonal")
},
future.seed = T)),ncol = 4)
toc()
}
for(l in 1:length(p.seq)){
tic()
bw_comparison_OU_m0[[l]]      = matrix(t(future_sapply(1:length(H[[l]]), FUN = function(k)
{
bandwidth_evaluation(H[[l]][k], p.seq[l], p.eval, n.seq, N,
cov.ou, list(theta = theta, sigma = sigma),
OU, list(alpha = theta, sigma = sigma, x0 = 0),
eps.arg = list(sd = sd), m = m)
},
future.seed = T)),ncol = 4)
cat("p =", p.seq[l], "done.")
bw_comparison_OU_m0_full[[l]] = matrix(t(future_sapply(1:length(H[[l]]), FUN = function(k)
{
bandwidth_evaluation(H[[l]][k], p.seq[l], p.eval, n.seq, N,
cov_ou, list(theta = theta, sigma = sigma),
OU, list(alpha = theta, sigma = sigma, x0 = 0),
eps.arg = list(sd = sd), m = m, grid.type = "without diagonal")
},
future.seed = T)),ncol = 4)
toc()
}
for(l in 1:length(p.seq)){
tic()
bw_comparison_OU_m0[[l]]      = matrix(t(future_sapply(1:length(H[[l]]), FUN = function(k)
{
bandwidth_evaluation(H[[l]][k], p.seq[l], p.eval, n.seq, N,
cov_ou, list(theta = theta, sigma = sigma),
OU, list(alpha = theta, sigma = sigma, x0 = 0),
eps.arg = list(sd = sd), m = m)
},
future.seed = T)),ncol = 4)
cat("p =", p.seq[l], "done.")
bw_comparison_OU_m0_full[[l]] = matrix(t(future_sapply(1:length(H[[l]]), FUN = function(k)
{
bandwidth_evaluation(H[[l]][k], p.seq[l], p.eval, n.seq, N,
cov_ou, list(theta = theta, sigma = sigma),
OU, list(alpha = theta, sigma = sigma, x0 = 0),
eps.arg = list(sd = sd), m = m, grid.type = "without diagonal")
},
future.seed = T)),ncol = 4)
toc()
}
library(tidyverse)
library(plotly)
library(lubridate)
library(hms)
library(biLocPol) # please install this package from Github first. See "README.md" file for instructions
library(future.apply)
my_theme = theme_grey(base_size = 15) +
theme(plot.title = element_text(size = 14))
load("weather/data/weather_data_raw.RData")
N$DATUM = str_split_i(N$MESS_DATUM, pattern = " ", i = 1) |> ymd()
tage = c(1, 4, 8, 12, 15, 18, 22, 25, 29)
N_full = N[-(1:6),]
N = N %>%
filter(TAG %in% tage)
N |>
filter(TAG %in% c(1, 8, 15, 22, 29)) |>
ggplot() +
geom_line(aes(x = UHRZEIT, y = TT_10, group = JAHR*TAG, colour = JAHR), alpha = .4) +
facet_wrap(MONAT ~.)
# Figure 3.12: Temperature curves in January
N |>
filter(MONAT == 1) |>
ggplot() +
geom_line(aes(x = UHRZEIT, y = TT_10, group = JAHR*TAG, colour = JAHR), alpha = .6) +
labs(y = "Temp. in C°", x = "hours", title = "Temp. in August", colour = "year") +
my_theme
ggsave("weather/grafics/january_temp_curves.pdf", device = "pdf", width = 5, height = 3.8, unit = "in")
# (b): Temperature curves in July
N |>
filter(TAG %in% tage,
MONAT == 7) |>
ggplot() +
geom_line(aes(x = UHRZEIT, y = TT_10, group = JAHR*TAG, colour = JAHR), alpha = .6) +
labs(y = "Temp. in C°", x = "hours", title = "Temp. in July", colour = "year") +
my_theme
ggsave("weather/grafics/july_temp_curves.pdf", device = "pdf", width = 5, height = 3.8, unit = "in")
# pivot wider
N_wide = N |>
filter(TAG %in% tage) |>  # No consecutive days
mutate(UHRZEIT = as.character(UHRZEIT)) |>
select(JAHR, MONAT, TAG, UHRZEIT, TT_10) |>
pivot_wider(names_from = UHRZEIT,
values_from = TT_10)
Y_all = N_full |>
mutate(UHRZEIT = as.character(UHRZEIT)) |>
select(JAHR, MONAT, TAG, UHRZEIT, TT_10) |>
pivot_wider(names_from = UHRZEIT, values_from = TT_10) |>
filter(MONAT == 4) |>
select(-(1:3))
empirical_cov_all = Y_all |>
as.data.frame() |>
observation_transformation(na.rm = T, grid.type = "full")
empirical_cov_filtered = N_wide |>
filter(MONAT == 4) |>
select(-(1:3)) |>
as.data.frame() |>
observation_transformation(na.rm = T, grid.type = "full")
df_all = tibble(empirical_cov_all, empirical_cov_filtered, observation_grid(144, comp = "full"))
# grafic not contained in paper
plot_ly(df_all, size = .4) |>
add_markers(x = ~Var1, y = ~Var2, z = ~empirical_cov_all) |>
add_markers(x = ~Var1, y = ~Var2, z = ~empirical_cov_filtered, alpha = 0.4)
#### NA Count #####
N |>  summarise(.by = c(JAHR, MONAT, TAG),
n = n(), mean = mean(TT_10)) |>
filter(n == 144) |>
summarise(.by = MONAT,
n = n()) |>
arrange(MONAT)
cov_estimation = function(month, weights = W, nw =  N_wide){
y = nw |>
filter(MONAT == month) |>
select(-(1:3))
z = y |>
as.data.frame() |> # TODO: fix this in biLocPol
observation_transformation(na.rm = T)
eval_weights(weights, z)
}
N_wide |>
filter(MONAT == 3) |>
select(-(1:3)) |> is.na() |> sum()
##### calculate weights #####
p.eval = 72
W = local_polynomial_weights(144, 0.2, p.eval, T, m = 1)
Wh05 = local_polynomial_weights(144, 0.5, p.eval, T, m = 1)
Wh01 = local_polynomial_weights(144, 0.1, p.eval, T, m = 1)
eval_time = N$UHRZEIT[1:146][seq(2, 144, 2)]
###### January ######
# Figure 9a: temp curves in January
N |>  filter(TAG %in% c(1, 15, 29),
MONAT == 1) |>
ggplot() +
geom_line(aes(x = UHRZEIT, y = TT_10, group = JAHR*TAG, colour = JAHR), alpha = .7) +
labs(y = "Temp. in C°", x = "hours", title = "Temp. in January", colour = "year") +
theme(text = element_text(size = 18))
g_hat1 = cov_estimation(1)
var_hat1 = diag(g_hat1)
var_est1 = tibble(var_hat = var_hat1, x = eval_time)
var_est1 |>
ggplot(aes(x = x, y = sqrt(var_hat1))) +
geom_line(size = .6) +
lims(y = c(0.2, 5)) +
labs(y = NULL, x = "hour", title = "Std. deviation of temperatur in January") +
theme(text = element_text(size = 18))
cov_est_df1 = data.frame(x = W$x.eval, y = W$x.eval, z = g_hat1)
cs2 = list(c(0, 1), c("lightblue", "darkred"))
# Plot of Covariance estimation: Not in Paper
plot_ly(cov_est_df1, x = ~x, y = ~y, z = ~g_hat1, size = .4) |>
add_surface(colorscale = cs2, alpha = .3) |>
layout(scene = list(xaxis = list(title = ""),
yaxis = list(title = ""),
zaxis = list(title = "")))
temp = matrix(diag(g_hat1), p.eval, p.eval)
cor_hat1 = g_hat1 / sqrt( temp * t(temp) )
# Figure 11a
plot_ly(cov_est_df1, x = ~x*24, y = ~y*24, z = ~cor_hat1, size = .4) |>
add_surface(colorscale = cs2, alpha = .3) |>
layout(scene = list(xaxis = list(title = ""),
yaxis = list(title = ""),
zaxis = list(title = "")))
# 3.14
plot_ly(cov_est_df1, x = ~x*24, y = ~y*24, z = ~cor_hat1, size = .4) |>
add_surface(colorscale = cs2, alpha = .3) |>
layout(scene = list(xaxis = list(title = ""),
yaxis = list(title = ""),
zaxis = list(title = "")))
###### July ######
g_hat = cov_estimation(7)
var_hat = diag(g_hat)
var_est = tibble(var_hat, x = eval_time)
var_est |>
ggplot(aes(x = x, y = sqrt(var_hat))) +
geom_line(linewidth = .7) +
lims(y = c(0.2, 5)) +
labs(y = NULL, x = "hour", title = "Std. deviation of temperatur in August") +
theme(legend.position = "none",
text = element_text(size = 18))
cov_est_df = data.frame(x = W$x.eval, y = W$x.eval, z = g_hat)
cs2 = list(c(0, 1), c("lightblue", "darkred"))
# Plot of Covariance Kernel: Not in Paper
plot_ly(cov_est_df, x = ~x, y = ~y, z = ~g_hat, size = .4) |>
add_surface(colorscale = cs2, alpha = .3) |>
layout(scene = list(xaxis = list(title = ""),
yaxis = list(title = ""),
zaxis = list(title = "")))
temp = matrix(diag(g_hat), p.eval, p.eval)
cor_hat = g_hat / sqrt( temp * t(temp) )
# Figure 11b: Plot of Correlation in August.
plot_ly(cov_est_df, x = ~x*24, y = ~y*24, z = ~cor_hat, size = .4) |>
add_surface(colorscale = cs2, alpha = .3) |>
layout(scene = list(xaxis = list(title = ""),
yaxis = list(title = ""),
zaxis = list(title = "")))
###### July ######
g_hat = cov_estimation(7)
var_hat = diag(g_hat)
var_est = tibble(var_hat, x = eval_time)
var_est |>
ggplot(aes(x = x, y = sqrt(var_hat))) +
geom_line(linewidth = .7) +
lims(y = c(0.2, 5)) +
labs(y = NULL, x = "hour", title = "Std. deviation of temperatur in August") +
theme(legend.position = "none",
text = element_text(size = 18))
cov_est_df = data.frame(x = W$x.eval, y = W$x.eval, z = g_hat)
cs2 = list(c(0, 1), c("lightblue", "darkred"))
# Plot of Covariance Kernel: Not in Paper
plot_ly(cov_est_df, x = ~x, y = ~y, z = ~g_hat, size = .4) |>
add_surface(colorscale = cs2, alpha = .3) |>
layout(scene = list(xaxis = list(title = ""),
yaxis = list(title = ""),
zaxis = list(title = "")))
temp = matrix(diag(g_hat), p.eval, p.eval)
cor_hat = g_hat / sqrt( temp * t(temp) )
# Plot of Correlation in July
plot_ly(cov_est_df, x = ~x*24, y = ~y*24, z = ~cor_hat, size = .4) |>
add_surface(colorscale = cs2, alpha = .3) |>
layout(scene = list(xaxis = list(title = ""),
yaxis = list(title = ""),
zaxis = list(title = "")))
##### Figure 3.14(b) #####
plot_ly(cov_est_df, x = ~x*24, y = ~y*24, z = ~cor_hat, size = .4) |>
add_surface(colorscale = cs2, alpha = .3) |>
layout(scene = list(xaxis = list(title = ""),
yaxis = list(title = ""),
zaxis = list(title = "")))
###### std_deviation ######
sd_tibble_m1h02 = sapply(1:12,
function(m){
est = cov_estimation(m) |> diag() |> sqrt()
}) |>
as_tibble()
sd_tibble_m1h05 = sapply(1:12,
function(m){
est = cov_estimation(m, weights = Wh05) |> diag() |> sqrt()
}) |> as_tibble()
sd_tibble_m1h01 = sapply(1:12,
function(m){
est = cov_estimation(m, weights = Wh01) |> diag() |> sqrt()
}) |> as_tibble()
sd_tibble = sd_tibble_m1h01 |>
rbind(sd_tibble_m1h02, sd_tibble_m1h05) |>
mutate(time = rep(eval_time, 3),
h = gl(3, 72, labels = c("144", "288", "720"))) |>
pivot_longer(cols = 1:12,
names_to = "month",
values_to = "sd",
cols_vary = "slowest") |>
mutate(month = gl(12, 72,
labels = c("Jan", "Feb", "Mar", "Apr",
"May", "Jun", "Jul", "Aug",
"Sep", "Oct", "Nov", "Dec")) |> rep(each = 3))
sd_tibble$time  = sd_tibble$time |> as.POSIXct(format = "%H:%M")
# Figure 10: all standard deviations.
sd_tibble |>
ggplot(aes(x = time, y = sd, lty = h, col = h)) +
geom_line(linewidth = .8) +
lims(y = c(0.2, 6)) +
labs(y = NULL, x = NULL) +
theme(text = element_text(size = 18)) +
facet_wrap(.~month, nrow = 3) +
scale_linetype_manual(values = c(2,5,4), name = "h (min)") +
scale_color_manual(values = 1:3, name = "h (min)") +
scale_x_datetime(date_breaks = "8 hours", date_labels = "%H:%M")
ggsave("weather/grafics/sd_all_months.pdf", device = "pdf", unit = "in", width = 9, height = 6)
rm(W, Wh01, Wh05)
save.image("weather/data/weather_covariace_results.RData")
